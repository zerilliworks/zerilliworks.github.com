<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Emerging Technology | Zerillian Engineering]]></title>
  <link href="http://blog.zerilliworks.net/blog/categories/emerging-technology/atom.xml" rel="self"/>
  <link href="http://blog.zerilliworks.net/"/>
  <updated>2013-08-29T00:21:40-04:00</updated>
  <id>http://blog.zerilliworks.net/</id>
  <author>
    <name><![CDATA[Armand Zerilli]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[De-Emphasizing the Server (Preface)]]></title>
    <link href="http://blog.zerilliworks.net/blog/2013/08/28/de-emphasizing-the-server-preface/"/>
    <updated>2013-08-28T23:20:00-04:00</updated>
    <id>http://blog.zerilliworks.net/blog/2013/08/28/de-emphasizing-the-server-preface</id>
    <content type="html"><![CDATA[<p>Only as a little introduction and to prove I still pay attention to things, I'll offer a breif commentary on a fascinating area of web engineering.</p>

<p>Being a little guy in this business, I have only the level of resources that entitles me to complain that AWS is too expensive (Read: web hosting budget is $30 monthly.) The engineer's mindset, however, is free (as in beer, it takes a long time to learn). You know what else is free? <em>Your visitor's browsers.</em></p>

<!-- more -->


<p>Even in the case of this little website, my readers point browsers over here that are backed with enough CPU cores to do the work of a large Amazon EC2 instance. For higher traffic sites, there might be thousands of cores and terabytes of memory in play.</p>

<p>Of course, I'd never hoover up all of a browser's resources. Technical constraints notwithstanding, it's a shitty thing to do. But what if I could just take an extra sliver of CPU and RAM from each of my users and combine it into something powerful?</p>

<p>Enter <a href="http://www.w3.org/TR/workers/">Web Workers</a>, <a href="http://www.webrtc.org">WebRTC</a>, and their bretheren. Asynchronous tasks and peer-to-peer connectivity in the browser. The implications here are huge. It gives me spine shivers.</p>

<p>I can spin off little Web Workers to, say, create a keyword index for a new status update or get link previews without my server fetching them first, or even help distribute static assets. Hell, I could have browsers run a site themselves just by seeding a JavaScript file and some images via a CDN. Just imagine what a <em>completely decentralized infrastructure</em> would look like. Web browsers do the work, the backend just keeps shit straightened up.</p>

<h3>Is your mind not as blown as mine is?</h3>

<p>I'll be attending a meetup to discuss these very topics. I'm excited enough to write about it beforehand. The ideas themselves warrant some deep though and admiration, so I'll be researching these topics heavily. If this technology can be packaged up in an accesible way, then exceeding bandwidth may be a thing of the past. Perhaps I'll never have to toss thousands of dollars to a hosting company or black-out my apps if a server gets gimped. It's a topic I intend to research, test, and report on further. I'd love to do an in-depth write up of potential implementations and features achievable with such new capabilities.</p>

<p>To think that my users can one day share the computational love and in the process shave down my hosting bill...  That kind of thing keeps me up at night.</p>
]]></content>
  </entry>
  
</feed>
